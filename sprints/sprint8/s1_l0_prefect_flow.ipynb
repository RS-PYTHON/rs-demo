{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d398824b",
   "metadata": {},
   "source": [
    "This demo uses the implemented story RSPY-120.\n",
    "\n",
    "ASSUMPTION: All the files from CADIP and ADGS mockup stations are already ingested and well published in the catalog. The ingestion of these files can be performed by running the demo prefect_flows_with_catalog_support from sprint_7 prior running this demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6fd57-cb01-4ed4-a9ba-fcd0a99c2a41",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3eac21-8783-4ff8-a2a6-bf9c8a751b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Get the RS-Server website URL. \n",
    "# Note: this is None in local mode, we rather use the env vars RSPY_HOST_CADIP, RSPY_HOST_CATALOG, ...\n",
    "url = os.getenv(\"RSPY_WEBSITE\")\n",
    "\n",
    "# Local mode or hybrid/cluster\n",
    "local_mode = (os.getenv(\"RSPY_LOCAL_MODE\") == \"1\")\n",
    " \n",
    "# Manually enter S3 access and secret key.\n",
    "# This is needed only for manual operation in this demo. This is not needed by rs-client.\n",
    "if not os.getenv(\"S3_ACCESSKEY\"):\n",
    "    os.environ[\"S3_ACCESSKEY\"] = getpass.getpass(f\"Enter S3 access key for {os.environ['S3_ENDPOINT']!r}:\")\n",
    "if not os.getenv(\"S3_SECRETKEY\"):\n",
    "    os.environ[\"S3_SECRETKEY\"] = getpass.getpass(f\"Enter S3 secret key for {os.environ['S3_ENDPOINT']!r}:\")\n",
    "\n",
    "# In hybrid/cluster mode: read the API key\n",
    "apikey = os.getenv(\"RSPY_APIKEY\")\n",
    "HEADERS={}\n",
    "if local_mode:\n",
    "    url_dpr_sim = \"http://dpr-simulator:8000\"\n",
    "else:\n",
    "    url_dpr_sim = \"http://mockup-processor-dpr-svc.processing.svc.cluster.local:8080\"\n",
    "    if not apikey:\n",
    "        apikey = getpass.getpass(f\"Enter your API key from {url!r}:\")\n",
    "    HEADERS={\"headers\": {\"x-api-key\": apikey}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaca0c8",
   "metadata": {},
   "source": [
    "Install the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66feca8c-8437-433f-a752-0c7f092014ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrument these notebook cells with OpenTelemetry (optional)\n",
    "from opentelemetry import trace\n",
    "otel_tracer = trace.get_tracer(\"my.notebook.trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe21c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are the same products as this demo will process in the final catalog bucket\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "if local_mode:\n",
    "    delete_files = True\n",
    "else:\n",
    "    delete_files = input(\"Before running the demo, check if previous results are in the final bucket. If these are to be found, should they be removed (optional)? (y/n): \").lower().strip() == 'y'\n",
    "\n",
    "s3_dir = \"PRODUCTS_DEMO_SPRINT_8\"\n",
    "\n",
    "s3_session = boto3.session.Session()\n",
    "s3_client = s3_session.client(\n",
    "    service_name=\"s3\",\n",
    "    aws_access_key_id=os.environ[\"S3_ACCESSKEY\"],\n",
    "    aws_secret_access_key=os.environ[\"S3_SECRETKEY\"],\n",
    "    endpoint_url=os.environ[\"S3_ENDPOINT\"],\n",
    "    region_name=os.environ[\"S3_REGION\"],\n",
    ")\n",
    "\n",
    "bucket_name = \"rs-cluster-catalog\"\n",
    "none_found = True\n",
    "for bucket in s3_client.list_buckets()[\"Buckets\"]:\n",
    "    if bucket_name != bucket[\"Name\"]:\n",
    "        continue\n",
    "    if 'Contents' in s3_client.list_objects(Bucket=bucket_name):\n",
    "        objects = s3_client.list_objects(Bucket=bucket_name)['Contents']\n",
    "        for obj in objects:\n",
    "            if s3_dir in obj[\"Key\"]:                \n",
    "                if delete_files:\n",
    "                    print(f\"Deleting {obj['Key']}\")\n",
    "                    s3_client.delete_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "                else:                          \n",
    "                    print(f\"{obj['Key']} modified on {obj['LastModified']}\") \n",
    "                    none_found = False\n",
    "print(\"No products found in the catalog bucket\") if none_found else print(\"\\nProducts found in the catalog bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107e143-03c4-4e99-9342-ec8301c19ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rs_client.rs_client import RsClient\n",
    "from rs_common.config import ECadipStation, EPlatform\n",
    "\n",
    "# Define the owner/user ID to read/write catalog collections.\n",
    "# Your API key must give you the read/write permissions for this owner ID.\n",
    "owner_id = \"DemoUser\"\n",
    "\n",
    "# Init a generic RS-Client instance. Pass the:\n",
    "#   - RS-Server website URL\n",
    "#   - API key\n",
    "#   - Owner ID\n",
    "#   - Logger (optional, a default one can be used)\n",
    "generic_client = RsClient(url, apikey, owner_id, logger=None)\n",
    "\n",
    "# From this generic instance, get an Auxip client instance\n",
    "# auxip_client = generic_client.get_auxip_client() # not used in this demo\n",
    "\n",
    "# Or get a Cadip client instance. Pass the cadip station and the platforms.\n",
    "cadip_station = ECadipStation.CADIP\n",
    "cadip_client = generic_client.get_cadip_client(cadip_station)\n",
    "\n",
    "# Or get a Stac client instance\n",
    "stac_client = generic_client.get_stac_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab23ff-b2e7-4b16-a590-6a036cc4f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Clean previous executions\n",
    "requests.delete(f\"{stac_client.href_catalog}/catalog/collections/DemoUser:s1_dpr\", **HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487488df-a320-4ba3-9782-9164843cfdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Search cadip sessions by date interval\n",
    "start_date = datetime(2014, 1, 1, 12, 0, 0)\n",
    "stop_date = datetime(2024, 1, 1, 12, 0, 0)\n",
    "platforms = [EPlatform.S1A, EPlatform.S2B]\n",
    "sessions = cadip_client.search_sessions(timeout=30, start_date=start_date, stop_date=stop_date, platforms=platforms)\n",
    "\n",
    "# Keep the first one\n",
    "session_id = sessions[0][\"id\"]\n",
    "print (session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7263f-b07d-4673-b6d3-301b035e76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: all the files from CADIP and ADGS server are well ingested in the catalog  as well as in the buckets\n",
    "# Note: the S3_ACCESSKEY, S3_SECRETKEY and S3_ENDPOINT are given in the docker-compose.yml file.\n",
    "with otel_tracer.start_as_current_span(\"nb.run-flow-s1_l0\") as span:\n",
    "    \n",
    "    from rs_workflows.s1_l0 import (\n",
    "        s1_l0_flow,\n",
    "        PrefectS1L0FlowConfig,\n",
    "    )\n",
    "    \n",
    "    mission = \"s1\"\n",
    "    s3_storage = f\"s3://rs-cluster-final/{s3_dir}/\"\n",
    "    temp_s3_storage = f\"s3://rs-cluster-temp/{s3_dir}/\"\n",
    "    \n",
    "    # the type of the prducts that the DPR should process\n",
    "    product_types = [\"S1SEWRAW\", \"S1SIWRAW\", \"S1SSMRAW\", \"S1SWVRAW\"]\n",
    "\n",
    "    # gather the data from ADGS. Excerpt from the RSPY-120 user story:\n",
    "    # \"3. search in the STAC collection rs-ops/s1_aux for the three required AUX\n",
    "    # items (given that RSPY-115 has filled the collection). As we don't know yet the\n",
    "    # rules that will be specified by DPR to retrieve the correct AUX data, we will for\n",
    "    # now hardcode the AUX file names as below:\n",
    "    adgs_files = [\n",
    "        \"S1A_AUX_PP2_V20200106T080000_G20200106T080000.SAFE\",\n",
    "        \"S1A_OPER_MPL_ORBPRE_20200409T021411_20200416T021411_0001.EOF\",\n",
    "        \"S1A_OPER_AUX_RESORB_OPOD_20210716T110702_V20210716T071044_20210716T102814.EOF\",\n",
    "    ]\n",
    "    \n",
    "    s1_l0_flow(\n",
    "            PrefectS1L0FlowConfig(\n",
    "                stac_client,\n",
    "                url_dpr_sim,\n",
    "                mission,\n",
    "                session_id,\n",
    "                product_types,\n",
    "                adgs_files,\n",
    "                s3_storage,\n",
    "                temp_s3_storage,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715391d5-7a12-4a8f-bd33-4ec37e3b304b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
