{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d398824b",
   "metadata": {},
   "source": [
    "This demo uses the following user stories:\n",
    "- RSPY-25\n",
    "- RSPY-85\n",
    "- RSPY-100\n",
    "- RSPY-115\n",
    "- RSPY-139\n",
    "\n",
    "Basically, this demo ingests all the files from CADIP and ADGS stations within the catalog database. The name of the collections in the catalog will be:\n",
    "- for ADGS -> DemoUser_s1_aux\n",
    "- for CADIP -> DemoUser_s1_chunk\n",
    "\n",
    "NOTE: The demo removes these two collections from the catalog database before starting the ingestion, so be advised when launching it inside the cluster.\n",
    "NOTE: To run it inside the cluster, this demo as well as the rs-client-libraries have to be uploaded in the jupyter notebook running as a pod in the cluster. After the uploading, the rs-client-libraries has to be installed and the kernel should be restarted before running this demo. To install the rs-client-libraries, go to the directory where the wheel has been uploaded (the wheel may be created on local pc with 'poetry build --format wheel') and start the following 2 commands:\n",
    "#: pip uninstall -y rs_client-libraries && pip install rs_client_libraries-x.y.z-py3-none-any.whl "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6fd57-cb01-4ed4-a9ba-fcd0a99c2a41",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a08609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    " \n",
    "# S3 access\n",
    "if not os.getenv(\"S3_ACCESSKEY\"):\n",
    "    os.environ[\"S3_ACCESSKEY\"] = getpass.getpass(f\"Enter S3 access key for {os.environ['S3_ENDPOINT']!r}:\")\n",
    "if not os.getenv(\"S3_SECRETKEY\"):\n",
    "    os.environ[\"S3_SECRETKEY\"] = getpass.getpass(f\"Enter S3 secret key for {os.environ['S3_ENDPOINT']!r}:\")\n",
    " \n",
    "# API key authentication (not on local mode)\n",
    "if (os.getenv(\"RSPY_LOCAL_MODE\") != \"1\") and (not os.getenv(\"RSPY_APIKEY\")):\n",
    "    os.environ[\"RSPY_APIKEY\"] = getpass.getpass(f\"Enter your API key from {os.environ['RSPY_WEBSITE']!r}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d32d1-54e8-4ab2-9b6b-c0af28d2c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set local or cluster configuration\n",
    "import os\n",
    "\n",
    "if os.getenv(\"RSPY_LOCAL_MODE\") == \"1\":\n",
    "    url_catalog = \"http://rs-server-catalog:8000\"    \n",
    "    url = \"http://rs-server-{}:8000\"    \n",
    "    HEADERS={}\n",
    "    local_mode = True\n",
    "else:\n",
    "    url_catalog = os.environ[\"RSPY_WEBSITE\"]    \n",
    "    url = os.environ[\"RSPY_WEBSITE\"]\n",
    "    HEADERS={\"headers\": {\"x-api-key\": os.environ[\"RSPY_APIKEY\"]}}\n",
    "    local_mode = False\n",
    "\n",
    "print(f\"Using url for catalog: {url_catalog}\")\n",
    "print(f\"Using url for rs-server: {url}\")\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6657010",
   "metadata": {},
   "source": [
    "Install the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b556c-b548-4428-8fe3-3cca45754287",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3\n",
    "if local_mode:\n",
    "    try:\n",
    "        import rs_workflows\n",
    "    except ModuleNotFoundError:\n",
    "        !(cd $RSPY_WHL_DIR && pip install rs_client_libraries-*.whl) # install rs-client if missing\n",
    "        !opentelemetry-bootstrap -a install # install opentelemetry instrumentation for deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8aabc-0fe9-4dc9-85d1-f60665c54292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrument these notebook cells with OpenTelemetry (optional)\n",
    "from opentelemetry import trace\n",
    "otel_tracer = trace.get_tracer(\"my.notebook.trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7263f-b07d-4673-b6d3-301b035e76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with otel_tracer.start_as_current_span(\"nb.init-buckets\") as span:\n",
    "    \n",
    "    # We'll use boto3 to monitor the s3 bucket. \n",
    "    # Note: the S3_ACCESSKEY, S3_SECRETKEY and S3_ENDPOINT are given in the docker-compose.yml file.\n",
    "    import boto3\n",
    "    import os\n",
    "    \n",
    "    s3_session = boto3.session.Session()\n",
    "    s3_client = s3_session.client(\n",
    "        service_name=\"s3\",\n",
    "        aws_access_key_id=os.environ[\"S3_ACCESSKEY\"],\n",
    "        aws_secret_access_key=os.environ[\"S3_SECRETKEY\"],\n",
    "        endpoint_url=os.environ[\"S3_ENDPOINT\"],\n",
    "        region_name=os.environ[\"S3_REGION\"],\n",
    "    )\n",
    "    \n",
    "    buckets = [\"rs-cluster-temp\", \"rs-cluster-catalog\"] # bucket names under S3_ENDPOINT\n",
    "    bucket_dir = \"stations\"\n",
    "    bucket_url = f\"s3://{buckets[0]}/{bucket_dir}\"\n",
    "    \n",
    "    # Only in local mode\n",
    "    if local_mode:\n",
    "        \n",
    "        # If the bucket is already created, clear all files to start fresh for each demo. \n",
    "        for b in buckets:\n",
    "            if b in [bucket[\"Name\"] for bucket in s3_client.list_buckets()[\"Buckets\"]]:\n",
    "                if 'Contents' in s3_client.list_objects(Bucket=b):\n",
    "                    objects = s3_client.list_objects(Bucket=b)['Contents']\n",
    "                    for obj in objects:\n",
    "                        # clear up the bucket\n",
    "                        s3_client.delete_object(Bucket=b, Key=obj['Key'])\n",
    "            else:\n",
    "                s3_client.create_bucket(Bucket=b)\n",
    "        for b in buckets:\n",
    "            print(f\"Is {b} empty ?: \", 'Contents' not in s3_client.list_objects(Bucket=b))\n",
    "        \n",
    "        # Truncate the items table from catalog also if this is not the first run !\n",
    "        #docker exec -it catalog-db psql -U postgres -d catalog -c \"TRUNCATE items\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472719ef",
   "metadata": {},
   "source": [
    "The bucket \"rs-cluster-temp\" is used for this demo. Thus, the cadip and adgs prefect flows will be asking for the rs-server endpoints to download the files from the CADIP and ADGS stations and to upload them to \"s3://rs-cluster-temp/stations/\".\n",
    "After a successful upload to the s3 bucket, the update stac catalog service is called to update the catalog and to transfer the files from the temp bucket to the \"rs-cluster-catalog\" bucket.\n",
    "Two collections will be created in the catalog to publish the files:\n",
    "- ADGS: DemoUser_s1_aux\n",
    "- CADIP: DemoUser_s1_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ab37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the previous executions. Be advised about this step when running the demo in the cluster !\n",
    "with otel_tracer.start_as_current_span(\"nb.clean-previous\") as span:\n",
    "    requests.delete(f\"{url_catalog}/catalog/collections/DemoUser:s1_aux\", **HEADERS)\n",
    "    requests.delete(f\"{url_catalog}/catalog/collections/DemoUser:s1_chunk\", **HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user's collection first (this has to be done on client side)\n",
    "with otel_tracer.start_as_current_span(\"nb.create-collection\") as span:\n",
    "    from dataclasses import dataclass\n",
    "    import requests\n",
    "    \n",
    "    @dataclass\n",
    "    class Collection:\n",
    "        \"\"\"A collection for test purpose.\"\"\"\n",
    "    \n",
    "        user: str\n",
    "        name: str\n",
    "    \n",
    "        @property\n",
    "        def id_(self) -> str:\n",
    "            \"\"\"Returns the id.\"\"\"\n",
    "            return f\"{self.user}_{self.name}\"\n",
    "    \n",
    "        @property\n",
    "        def properties(self):\n",
    "            \"\"\"Returns the properties.\"\"\"\n",
    "            return {\n",
    "                \"id\": self.name,\n",
    "                \"type\": \"Collection\",\n",
    "                \"links\": [\n",
    "                    {\n",
    "                        \"rel\": \"items\",\n",
    "                        \"type\": \"application/geo+json\",\n",
    "                        \"href\": f\"http://localhost:8082/collections/{self.name}/items\",\n",
    "                    },\n",
    "                    {\"rel\": \"parent\", \"type\": \"application/json\", \"href\": \"http://localhost:8082/\"},\n",
    "                    {\"rel\": \"root\", \"type\": \"application/json\", \"href\": \"http://localhost:8082/\"},\n",
    "                    {\n",
    "                        \"rel\": \"self\",\n",
    "                        \"type\": \"application/json\",\n",
    "                        \"href\": f\"\"\"http://localhost:8082/collections/{self.name}\"\"\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"rel\": \"license\",\n",
    "                        \"href\": \"https://creativecommons.org/licenses/publicdomain/\",\n",
    "                        \"title\": \"public domain\",\n",
    "                    },\n",
    "                ],\n",
    "                \"extent\": {\n",
    "                    \"spatial\": {\"bbox\": [[-94.6911621, 37.0332547, -94.402771, 37.1077651]]},\n",
    "                    \"temporal\": {\"interval\": [[\"2000-02-01T00:00:00Z\", \"2000-02-12T00:00:00Z\"]]},\n",
    "                },\n",
    "                \"license\": \"public-domain\",\n",
    "                \"description\": \"Some description\",\n",
    "                \"stac_version\": \"1.0.0\",\n",
    "                \"owner\": user,\n",
    "            }\n",
    "        \n",
    "    user = \"DemoUser\"\n",
    "    mission = \"s1\"\n",
    "    \n",
    "    # Create the collections for DemoUser\n",
    "    # For ADGS station\n",
    "    collection_type = Collection(user, f\"{mission}_aux\")\n",
    "    response = requests.post(url_catalog + f\"/catalog/collections\", json=collection_type.properties, **HEADERS)\n",
    "    print(json.loads(response.content))\n",
    "    # For CADIP station\n",
    "    collection_type = Collection(user, f\"{mission}_chunk\")\n",
    "    response = requests.post(url_catalog + f\"/catalog/collections\", json=collection_type.properties, **HEADERS)\n",
    "    response.raise_for_status()\n",
    "    print(json.loads(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed1ee5-56eb-4f46-95fa-a7cb2015fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with otel_tracer.start_as_current_span(\"nb.run-flow-ingestion\") as span:\n",
    "    \n",
    "    from datetime import datetime\n",
    "    \n",
    "    from rs_workflows.common import (\n",
    "        PrefectFlowConfig,\n",
    "        download_flow,\n",
    "    )\n",
    "    \n",
    "    def run_flow(user, url, url_catalog, station, mission, tmp_local_download, bucket_url, api_key, no_of_tasks, start_date, stop_date, limit):\n",
    "        # start the prefect flow\n",
    "        download_flow(PrefectFlowConfig(user,\n",
    "                                        url,\n",
    "                                        url_catalog,\n",
    "                                        station,\n",
    "                                        mission,\n",
    "                                        tmp_local_download,\n",
    "                                        bucket_url,\n",
    "                                        api_key,\n",
    "                                        no_of_tasks,\n",
    "                                        datetime.strptime(start_date, \"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                                        datetime.strptime(stop_date, \"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                                        limit\n",
    "                )\n",
    "    )\n",
    "    \n",
    "    stations = [\"CADIP\", \"ADGS\"]\n",
    "    \n",
    "    tmp_local_download = \"/tmp/{}_tmp\"\n",
    "    # Number of tasks to be run in parallel. The maximum number of tasks in parallel is given by the number of tasks requested in rs-client-libraries prefect flow\n",
    "    # download_flow from rs_workflows.common package\n",
    "    no_of_tasks = 15\n",
    "    # Use the limit parameter to download a maximum number of files. In this demo case, all files are downloaded, thus the limit should be None\n",
    "    limit = None\n",
    "    \n",
    "    for station in stations:\n",
    "        run_flow(user,\n",
    "                 url.format(station.lower()),\n",
    "                 url_catalog,\n",
    "                 station,\n",
    "                 mission,\n",
    "                 tmp_local_download.format(station),\n",
    "                 bucket_url + f\"/{station}\",\n",
    "                 os.environ.get(\"RSPY_APIKEY\", None),\n",
    "                 no_of_tasks,\n",
    "                 \"2014-01-01T12:00:00Z\",\n",
    "                 \"2024-02-20T12:00:00Z\",\n",
    "                 None\n",
    "                 )    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links where the files can be downloaded. A maximum of 20 links will be created\n",
    "with otel_tracer.start_as_current_span(\"nb.print-results\") as span:\n",
    "    import json\n",
    "    catalog_data = json.loads((requests.get(url_catalog.rstrip(\"/\") + f\"/catalog/collections/{user}:{mission}_aux/items?limit=20\", **HEADERS).content.decode()))\n",
    "    \n",
    "    for feature in catalog_data['features']:\n",
    "        print(requests.get(url_catalog.rstrip(\"/\") + f\"/catalog/collections/{user}:{mission}_aux/items/{feature['id']}/download/file\", **HEADERS).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e40c4-30b0-4c02-ba95-4348f347e397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
