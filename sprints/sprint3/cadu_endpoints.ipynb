{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b445d78-b8ce-459c-a34e-11af313fe1e3",
   "metadata": {},
   "source": [
    "# CADU endpoints demo\n",
    "\n",
    "In this demo we will call the rs-server CADU HTTP endpoints:\n",
    "\n",
    "  * List available CADU products\n",
    "  * Download some products into local storage and S3 bucket\n",
    "  * Monitor the download status from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8f49d4-b62b-419a-8868-9072a40962f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some variables\n",
    "endpoint=\"http://rs-server:8000/cadip/CADIP/cadu\" # rs-server host = the container name\n",
    "start=\"2014-01-01T12:00:00.000Z\"\n",
    "stop=\"2023-12-30T12:00:00.000Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50de3560-f30b-42b4-88ea-7ed93030fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ curl -X GET 'http://rs-server:8000/cadip/CADIP/cadu/list?start_date=2014-01-01T12:00:00.000Z&stop_date=2023-12-30T12:00:00.000Z' -H 'accept: application/json'\n",
      "{\"CADIP\":[[\"2b17b57d-fff4-4645-b539-91f305c27c69\",\"DCS_04_S1A_20231121072204051312_ch1_DSDB_00001.raw\"],[\"2b17b57d-fff4-4645-b539-91f305c27c60\",\"DCS_04_S1A_20231121072204051312_ch1_DSDB_00002.raw\"],[\"2b17b57d-fff4-4645-b539-91f305c27c61\",\"DCS_04_S1A_20231121072204051312_ch1_DSDB_00003.raw\"],[\"2b17b57d-fff4-4645-b539-91f305c27c62\",\"DCS_04_S1A_20231121072204051312_ch1_DSDB_00004.raw\"],[\"2b17b57d-fff4-4645-b539-91f305c27c63\",\"DCS_04_S1A_20231121072204051312_ch1_DSDB_00005.raw\"],[\"2b17b57d-fff4-4645-b539-91f305c27c64\",\"DCS_04_S1A_20231121072204051312_ch1_DSDB_00006.raw\"],[\"2b17b57d-fff4-4645-b539-91f305c27c65\",\"DCS_04_S1A_20231121072204051312_ch1_DSDB_00007.raw\"],[\"some_id_2\",\"DCS_04_S1A_20231121072204051312_ch1_DSDB_00060.raw\"],[\"some_id_3\",\"DCS_04_S1A_20231121072204051312_ch2_DSDB_00046.raw\"],[\"some_id_4\",\"DCS_04_S1A_20231121072204051312_ch2_DSDB_00060.raw\"]]}"
     ]
    }
   ],
   "source": [
    "# From a terminal, to list the available CADU products, we would use the curl command:\n",
    "!set -x && curl -X GET \"{endpoint}/list?start_date={start}&stop_date={stop}\" -H \"accept: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9e3adc-0ace-4343-8b47-3660aee4cd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   [   '2b17b57d-fff4-4645-b539-91f305c27c69',\n",
      "        'DCS_04_S1A_20231121072204051312_ch1_DSDB_00001.raw'],\n",
      "    [   '2b17b57d-fff4-4645-b539-91f305c27c60',\n",
      "        'DCS_04_S1A_20231121072204051312_ch1_DSDB_00002.raw'],\n",
      "    [   '2b17b57d-fff4-4645-b539-91f305c27c61',\n",
      "        'DCS_04_S1A_20231121072204051312_ch1_DSDB_00003.raw']]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# But let's do it in python so it's easier to parse results\n",
    "import requests\n",
    "import pprint \n",
    "\n",
    "# Call the \"list\" endpoint\n",
    "data = requests.get(f\"{endpoint}/list\", {\"start_date\": start, \"stop_date\": stop})\n",
    "assert data.status_code == 200\n",
    "\n",
    "# Get the returned products as (id,name) lists\n",
    "products = data.json()[\"CADIP\"]\n",
    "assert len(products) == 10\n",
    "\n",
    "# Print the first n products\n",
    "pprint.PrettyPrinter(indent=4).pprint(products[:3])\n",
    "print(\"...\")\n",
    "\n",
    "# Keep only the names\n",
    "product_names = [name for id, name in products]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ee015f-5e13-47bd-ad7d-81baff771a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'available_at_station': '2023-11-26T17:01:39.528000',\n",
      "        'cadu_id': '2b17b57d-fff4-4645-b539-91f305c27c69',\n",
      "        'db_id': 1,\n",
      "        'download_start': None,\n",
      "        'download_stop': None,\n",
      "        'name': 'DCS_04_S1A_20231121072204051312_ch1_DSDB_00001.raw',\n",
      "        'status': 'NOT_STARTED',\n",
      "        'status_fail_message': None},\n",
      "    {   'available_at_station': '2023-11-26T17:01:39.528000',\n",
      "        'cadu_id': '2b17b57d-fff4-4645-b539-91f305c27c60',\n",
      "        'db_id': 2,\n",
      "        'download_start': None,\n",
      "        'download_stop': None,\n",
      "        'name': 'DCS_04_S1A_20231121072204051312_ch1_DSDB_00002.raw',\n",
      "        'status': 'NOT_STARTED',\n",
      "        'status_fail_message': None}]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# The \"list\" endpoint has initialised the database with the products info.\n",
    "# Call the \"status\" endpoint to get the info from the products name.\n",
    "all_status = []\n",
    "for name in product_names:\n",
    "    data = requests.get(f\"{endpoint}/status\", {\"name\": name})\n",
    "    assert data.status_code == 200\n",
    "    all_status.append (data.json())\n",
    "\n",
    "# Print the first n status\n",
    "pprint.PrettyPrinter(indent=4).pprint(all_status[:2])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03d397-7737-4d9d-ad11-235c4beed428",
   "metadata": {},
   "source": [
    "---\n",
    "**NOTE**\n",
    "\n",
    "You can also monitor the database using pgAdmin.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb527198-3896-4447-b758-ce54f2ae70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.34.25-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.25 (from boto3)\n",
      "  Downloading botocore-1.34.25-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.25->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.25->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.25->boto3) (1.16.0)\n",
      "Downloading boto3-1.34.25-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.25-py3-none-any.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.34.25 botocore-1.34.25 jmespath-1.0.1 s3transfer-0.10.0\n"
     ]
    }
   ],
   "source": [
    "# We'll use boto3 to monitor the s3 bucket.\n",
    "# Note: the S3_ACCESSKEY, S3_SECRETKEY and S3_ENDPOINT are given in the docker-compose.yml file.\n",
    "!pip install boto3\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "s3_session = boto3.session.Session()\n",
    "s3_client = s3_session.client(\n",
    "    service_name=\"s3\",\n",
    "    aws_access_key_id=os.environ[\"S3_ACCESSKEY\"],\n",
    "    aws_secret_access_key=os.environ[\"S3_SECRETKEY\"],\n",
    "    endpoint_url=os.environ[\"S3_ENDPOINT\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2064243b-e760-4e63-8cee-6696614caf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket name\n",
    "bucket_name = \"test-data\"\n",
    "\n",
    "# If the s3 bucket already exist, remove the existing products from it\n",
    "if bucket_name in [bucket[\"Name\"] for bucket in s3_client.list_buckets()[\"Buckets\"]]:\n",
    "    for name in product_names:\n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=name)\n",
    "\n",
    "# Else create the bucket\n",
    "else:\n",
    "    s3_client.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "# The local download directory is passed as an environment variable\n",
    "rspy_working_dir = os.environ[\"RSPY_WORKING_DIR\"]\n",
    "\n",
    "# Remove all local files if they exist\n",
    "from pathlib import Path\n",
    "for name in product_names:\n",
    "    file = Path (rspy_working_dir) / name\n",
    "    if file.is_file():\n",
    "        file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3549f2ca-cb6f-457f-a1cf-8b66e9426cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download everything to the local directory, not s3:\n",
      "NOT_STARTED:0 / IN_PROGRESS:1 / FAILED:0 / DONE:9\n",
      "NOT_STARTED:0 / IN_PROGRESS:0 / FAILED:0 / DONE:10\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch1_DSDB_00001.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch1_DSDB_00002.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch1_DSDB_00003.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch1_DSDB_00004.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch1_DSDB_00005.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch1_DSDB_00006.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch1_DSDB_00007.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch1_DSDB_00060.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch2_DSDB_00046.raw exists\n",
      "/local/download/DCS_04_S1A_20231121072204051312_ch2_DSDB_00060.raw exists\n",
      "\n",
      "Download everything again, but this time upload to S3:\n",
      "NOT_STARTED:0 / IN_PROGRESS:1 / FAILED:0 / DONE:9\n",
      "NOT_STARTED:0 / IN_PROGRESS:0 / FAILED:0 / DONE:10\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch1_DSDB_00001.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch1_DSDB_00002.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch1_DSDB_00003.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch1_DSDB_00004.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch1_DSDB_00005.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch1_DSDB_00006.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch1_DSDB_00007.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch1_DSDB_00060.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch2_DSDB_00046.raw exists\n",
      "s3://test-data/DCS_04_S1A_20231121072204051312_ch2_DSDB_00060.raw exists\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Call the CADIP endpoint to download one product in background \n",
    "# and upload it (optional) to the S3 bucket.\n",
    "async def download_one(name: str, save_to_s3: bool):\n",
    "\n",
    "    params = {\"name\": name, \"local\": rspy_working_dir}\n",
    "    # obs = the bucket URL, if requested\n",
    "    if save_to_s3:\n",
    "        params[\"obs\"] = f\"s3://{bucket_name}\"\n",
    "\n",
    "    data = requests.get(endpoint, params)\n",
    "    assert data.status_code == 200\n",
    "\n",
    "# In parallel, call the \"status\" endpoint to get and print the download status.\n",
    "async def print_status():\n",
    "\n",
    "    # Wait a second if the staus need to be passed \n",
    "    # from DONE to NOT_STARTED if we download several times.\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "    all_done = False\n",
    "    while not all_done: \n",
    "\n",
    "        # Count the number of products not started, in progres etc ...\n",
    "        all_status = {\"NOT_STARTED\": 0, \"IN_PROGRESS\": 0, \"FAILED\": 0, \"DONE\": 0}\n",
    "        for name in product_names:\n",
    "            \n",
    "            # Call the \"status\" endpoint\n",
    "            data = requests.get(f\"{endpoint}/status\", {\"name\": name})\n",
    "            assert data.status_code == 200\n",
    "            all_status[(data.json())[\"status\"]] += 1\n",
    "\n",
    "        # Print result\n",
    "        print (\" / \".join ([f\"{status}:{count}\" for status, count in all_status.items()]))\n",
    "\n",
    "        if all_status[\"DONE\"] == len(product_names):\n",
    "            all_done = True\n",
    "        else:\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "# Call everything in parallel\n",
    "async def download_all(save_to_s3: bool):\n",
    "    async with asyncio.TaskGroup() as group:\n",
    "        group.create_task (print_status())\n",
    "        for name in product_names:\n",
    "            group.create_task(download_one (name, save_to_s3))\n",
    "\n",
    "print (\"Download everything to the local directory, not s3:\")\n",
    "await (download_all(save_to_s3=False))\n",
    "\n",
    "# Check that the local files exist. \n",
    "# Wait 1 second before that or sometimes it bugs.\n",
    "await asyncio.sleep(1)\n",
    "for name in product_names:\n",
    "    file = Path (local_download_dir) / name    \n",
    "    if not file.is_file():\n",
    "        raise RuntimeException (f\"{file} is missing locally\")\n",
    "    print (f\"{file} exists\")\n",
    "\n",
    "print (\"\\nDownload everything again, but this time upload to S3:\")\n",
    "await (download_all(save_to_s3=True))\n",
    "\n",
    "# This time the local files are not kept locally, \n",
    "# but they should be uploaded into the S3 bucket.\n",
    "await asyncio.sleep(1)\n",
    "all_s3_filenames = [key[\"Key\"] for key in s3_client.list_objects(Bucket=bucket_name)['Contents']]\n",
    "for name in product_names:    \n",
    "    if not name in all_s3_filenames:\n",
    "        raise RuntimeException (f\"{file} is missing from the S3 bucket\")\n",
    "    print (f\"s3://{bucket_name}/{name} exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5462b2-f0c8-476c-ad56-1a814af85dbe",
   "metadata": {},
   "source": [
    "---\n",
    "**NOTE**\n",
    "\n",
    "You can also monitor the s3 bucket using the minio console: http://127.0.0.1:9001/browser with:\n",
    "\n",
    "  * Username: _minio_\n",
    "  * Password: _Strong#Pass#1234_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5d4303-1b6e-4472-9489-a028d318cad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeliness for:\n",
      "  - DCS_04_S1A_20231121072204051312_ch1_DSDB_00001.raw: 56 days, 15:36:08.625266\n",
      "  - DCS_04_S1A_20231121072204051312_ch1_DSDB_00002.raw: 56 days, 15:36:08.621716\n",
      "  - DCS_04_S1A_20231121072204051312_ch1_DSDB_00003.raw: 56 days, 15:36:08.628110\n",
      "  - DCS_04_S1A_20231121072204051312_ch1_DSDB_00004.raw: 56 days, 15:36:08.624966\n",
      "  - DCS_04_S1A_20231121072204051312_ch1_DSDB_00005.raw: 56 days, 15:36:08.743524\n",
      "  - DCS_04_S1A_20231121072204051312_ch1_DSDB_00006.raw: 56 days, 15:36:08.897286\n",
      "  - DCS_04_S1A_20231121072204051312_ch1_DSDB_00007.raw: 56 days, 15:36:09.043408\n",
      "  - DCS_04_S1A_20231121072204051312_ch1_DSDB_00060.raw: 56 days, 15:36:09.199569\n",
      "  - DCS_04_S1A_20231121072204051312_ch2_DSDB_00046.raw: 56 days, 17:17:27.394199\n",
      "  - DCS_04_S1A_20231121072204051312_ch2_DSDB_00060.raw: 56 days, 17:12:29.649524\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt_format = \"%Y-%m-%dT%H:%M:%S.%f\" # %z\n",
    "\n",
    "# Check timeliness by substracting download stop date - publishing date.\n",
    "# Call the \"status\" endpoint.\n",
    "print (\"Timeliness for:\")\n",
    "for name in product_names:    \n",
    "    data = requests.get(f\"{endpoint}/status\", {\"name\": name})\n",
    "    assert data.status_code == 200\n",
    "    values = data.json()\n",
    "    publication = datetime.strptime (values[\"available_at_station\"], dt_format)\n",
    "    stop = datetime.strptime (values[\"download_stop\"], dt_format)\n",
    "    timeliness = stop - publication\n",
    "    print (f\"  - {name}: {timeliness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c002f-6453-43ae-82db-a4e08b911c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddfd8e-e32c-4f01-97ff-35d80c4d6900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
