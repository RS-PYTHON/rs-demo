{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c39c4ff-4dc2-4dcd-aed3-d1c3062bebe0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h1>RS-Server / RS-Client tutorial for the ESA checkpoint 0.1</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf9681-d649-4b33-8c79-021e39e4dd1b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we will see how to stage files, save them in the catalog, do it from a Prefect flow, run a simulated S1L0 processing from a Prefect flow  ... \n",
    "<mark>TODO: link to existing documentation that already explains these concepts ? Or copy/paste the documentation here ? \n",
    "Or write a simplified documentation here ?</mark>\n",
    "\n",
    "## <a id='TOC_TOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "    \n",
    " 1. [Check your installation](#check_your_installation)\n",
    " 1. [RsClient initialisation](#rsclient_initialisation)\n",
    " 1. [Call services manually](#call_services_manually)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf81275-831c-48e8-bca0-1086434dcbc4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='check_your_installation'></a>Check your installation\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d069303-fd50-49ea-9c47-9d23749806bd",
   "metadata": {},
   "source": [
    "### `rs-client-libraries` installation\n",
    "\n",
    "The `rs-client-libraries` Python library is the preferred way to access the RS-Server services from your environment. It is automatically installed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69708f8f-84ca-45fc-9379-313f193c44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rs_client\n",
    "import rs_common\n",
    "import rs_workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffce11f-fcf3-4514-a425-5ae2ecfca3b1",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cc16b-3dff-4909-9f72-2fb40834b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# In local mode, all your services are running locally.\n",
    "# In hybrid or cluster mode, we use the services deployed on the RS-Server website.\n",
    "# This configuration is set in an environment variable.\n",
    "local_mode = (os.getenv(\"RSPY_LOCAL_MODE\") == \"1\")\n",
    "\n",
    "# In local mode, print the services URL\n",
    "if local_mode:\n",
    "    print (f\"ADGS service: http://localhost:8001/docs\")\n",
    "    print (f\"CADIP service: http://localhost:8002/docs\")\n",
    "    print (f\"Catalog service: http://localhost:8003/api.html\")\n",
    "    print (f\"MinIO dashboard (object storage): http://localhost:9101 with user=minio password=Strong#Pass#1234\")\n",
    "    print (f\"Prefect dashboard (orchestrator): http://localhost:4200\")\n",
    "    print (f\"Grafana dashboard (logs, traces, metrics): http://localhost:3000/explore\")\n",
    "    url = None # not used\n",
    "\n",
    "# In hybrid or cluster mode, the RS-Server website is set in an environment variable.\n",
    "else:\n",
    "    url = os.environ[\"RSPY_WEBSITE\"]\n",
    "    print (f\"RS-Server website: {url}\")\n",
    "    print (f\"Create an API key: {url}/docs#/API-Key%20Manager/create_api_key_apikeymanager_auth_api_key_new_get\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287923f6-d486-472f-9809-750f4362da6e",
   "metadata": {},
   "source": [
    "### S3 buckets (object storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e7543-6ff4-4a0a-ae05-5e37d967f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp and final s3 buckets used by RS-Server\n",
    "TEMP_S3_BUCKET = \"rs-cluster-temp\"\n",
    "FINAL_S3_BUCKET = \"rs-cluster-catalog\"\n",
    "\n",
    "# In local mode, we need to create them manually in the local minio object storage\n",
    "if local_mode:\n",
    "    !pip install boto3\n",
    "    from resources.utils import create_s3_buckets\n",
    "    create_s3_buckets(TEMP_S3_BUCKET, FINAL_S3_BUCKET)\n",
    "\n",
    "# In hybrid or cluster mode, the buckets already exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9dd47a-36d5-405c-b993-5b21c1c6446f",
   "metadata": {},
   "source": [
    "---\n",
    "**<mark>TO BE DISCUSSED</mark>**\n",
    "\n",
    "In local mode, is it a good advice to tell the end-users to go to the MinIO, Prefect and Grafana dashboard ?\n",
    "\n",
    "Same question in hybrid/cluster mode, should we give these links and how to pass them ? (env variables ?)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23fe1d-8b50-488a-97d9-89af32a66ef5",
   "metadata": {},
   "source": [
    "### API key\n",
    "\n",
    "In hybrid and cluster mode, you need an API key to access the RS-Server services. You can create one from the link displayed in the previous cell, then enter it manually in the cell below. \n",
    "\n",
    "If you prefer to load it automatically in all your notebooks, you can: \n",
    "\n",
    "  * From your JupyterHub workspace, open the text file `~/.rspy` <mark>(TODO: name to be defined)</mark>\n",
    "  * Save your API key using this syntax:\n",
    "\n",
    "    ```bash\n",
    "    export RSPY_APIKEY=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx # replace by your value\n",
    "    ```\n",
    "\n",
    "  * Save and close the file.\n",
    "  * <mark>TO BE CONFIRMED: Reload your JupyterHub session from Menu -> File -> Log Out / or just</mark>\n",
    "  * <mark>Reload this notebook kernel from Menu -> Kernel -> Restart Kernel.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32c2ed-f3ad-4adc-9642-bbbfe6985f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.getenv(\"RSPY_APIKEY\")\n",
    "if (not local_mode) and (not apikey):\n",
    "    import getpass\n",
    "    apikey = getpass.getpass(f\"Enter your API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862e220-e83a-4a9f-aa37-d384347ced05",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='rsclient_initialisation'></a>RsClient initialisation\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "We are using Python RsClient instances to access the RS-Server services.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ca29b-1292-498b-94de-9191fc9458b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rs_client.rs_client import RsClient\n",
    "from rs_common.config import ECadipStation\n",
    "\n",
    "# Init a generic RS-Client instance. Pass the:\n",
    "#   - RS-Server website URL\n",
    "#   - API key\n",
    "#   - Logger (optional, a default one can be used)\n",
    "generic_client = RsClient(url, apikey, logger=None)\n",
    "\n",
    "# From this generic instance, get an Auxip client instance\n",
    "auxip_client = generic_client.get_auxip_client()\n",
    "\n",
    "# Or get a Cadip client instance. Pass the cadip station.\n",
    "cadip_station = ECadipStation.CADIP\n",
    "cadip_client = generic_client.get_cadip_client(cadip_station)\n",
    "\n",
    "# Or get a Stac client to access the catalog\n",
    "stac_client = generic_client.get_stac_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074e987-dda7-463c-9bd8-26e150cd870f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='call_services_manually'></a>Call services manually\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "In this section, we will see how to call manually these services: \n",
    "\n",
    "  * Search Auxip and Cadip stations for new files\n",
    "  * Stage these files\n",
    "  * Check the staging status\n",
    "  * Search Cadip sessions\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068b294-713f-4b25-b6b2-1b7db9a9c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "from rs_common.config import EDownloadStatus, EPlatform\n",
    "\n",
    "# Define a search interval\n",
    "start_date = datetime(2014, 1, 1, 12, 0, 0)\n",
    "stop_date = datetime(2024, 1, 1, 12, 0, 0)\n",
    "\n",
    "# Timeout in seconds for the endpoints\n",
    "TIMEOUT = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86bfa53-fbd7-4c6f-ac47-4e151b643420",
   "metadata": {},
   "source": [
    "### Search Cadip sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81869f26-c21e-4359-a959-29534798e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search cadip sessions by date interval and platforms\n",
    "platforms = [EPlatform.S1A, EPlatform.S2B]\n",
    "sessions = cadip_client.search_sessions(TIMEOUT, start_date=start_date, stop_date=stop_date, platforms=platforms)\n",
    "\n",
    "session_count = len(sessions)\n",
    "assert session_count, \"We should have at least one Cadip session\"\n",
    "print (f\"Found {session_count} Cadip sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45253518-999f-4f2e-8759-d9a7f39a71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first cadip session. It is in the STAC format.\n",
    "print(f\"First Cadip session:\\n{json.dumps(sessions[0], indent=2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c7920-3942-4156-88a3-f503ddf7230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the Cadip sessions ID\n",
    "ids=[s[\"id\"] for s in sessions]\n",
    "print_ids=\"\\n\".join(ids)\n",
    "print(f\"Cadip sessions ID:\\n{print_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711fe8e-0cb6-4e9a-b0bd-42f76c97c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also search Cadip sessions by specific sessions ID, \n",
    "# rather than by date interval and platforms\n",
    "# e.g. get information for the cadip sessions #2 and #3\n",
    "search_ids=ids[1:3]\n",
    "search_sessions = cadip_client.search_sessions(TIMEOUT, session_ids=search_ids)\n",
    "print(f\"Cadip sessions information:\\n{json.dumps(search_sessions, indent=2)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f05d1-1c37-4abd-acd2-118490c25bd9",
   "metadata": {},
   "source": [
    "### Search Auxip and Cadip stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a113ddc-b3b1-4b35-98ab-86e586f9cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this using the Auxip then the Cadip client\n",
    "for client in [auxip_client, cadip_client]:\n",
    "\n",
    "    # Call the service to search stations for new files in the date interval.\n",
    "    files = client.search_stations(start_date, stop_date, TIMEOUT)\n",
    "    \n",
    "    file_count = len(files)\n",
    "    assert file_count, f\"We should have at least one {client.station_name} file\"\n",
    "    print (f\"Found {file_count} {client.station_name} files\\n\")\n",
    "\n",
    "    # Print the first file. It is in the STAC format.\n",
    "    print(f\"First {client.station_name} file:\\n{json.dumps(files[0], indent=2)}\\n\")\n",
    "\n",
    "    # By default, the files are returned sorted by the most recent first (by creation date)\n",
    "    ids=\"\\n\".join([f\"{f['properties']['created']} - {f['id']}\" for f in files[:10]])\n",
    "    print(f\"Most recent {client.station_name} IDs and datetimes:\\n{ids}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd078a49-5768-4291-99cb-1885de815391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort by +/- any property, e.g. by creation date ascending = the oldest first\n",
    "for client in [auxip_client, cadip_client]:    \n",
    "    files = client.search_stations(start_date, stop_date, TIMEOUT, sortby=\"+created\")\n",
    "    ids=\"\\n\".join([f\"{f['properties']['created']} - {f['id']}\" for f in files[:10]])\n",
    "    print(f\"Oldest {client.station_name} IDs and datetimes:\\n{ids}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b28f2-1a06-47ca-967c-1dba7d99aff3",
   "metadata": {},
   "source": [
    "### Stage Auxip and Cadip files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9389d-933b-4938-909a-9d24f62a8eb9",
   "metadata": {},
   "source": [
    "<mark>\n",
    "TO BE DISCUSSED: The temporary bucket name is hardcoded ? Should we give it in an env var ?\n",
    "There is only one temp bucket ?\n",
    "</mark>\n",
    "\n",
    "<mark>We will have conflicts if UserA and UserB stage the same file at the same time\n",
    "in the same s3 location, it will be staged only once. But then when UserA pushes the file in his collection,\n",
    "it will be deleted from the temp bucket, thus UserB cannot use it anymore.\n",
    "</mark>\n",
    "\n",
    "<mark>Maybe we should force UserA to use the s3 location s3://rs-cluster-temp/UserA/dirs/filename</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb9238c-13fe-4116-b87e-513903a18813",
   "metadata": {},
   "outputs": [],
   "source": [
    "staged_files = []\n",
    "for client in [auxip_client, cadip_client]:\n",
    "\n",
    "    # When searching stations, we can also limit the number of returned results.\n",
    "    # Let's keep only one file.\n",
    "    files = client.search_stations(start_date, stop_date, TIMEOUT, limit=1)\n",
    "    assert len(files) == 1\n",
    "\n",
    "    # We stage by filename = the file ID\n",
    "    first_filename = files[0][\"id\"]\n",
    "\n",
    "    # We stage this file = download it into a temporary s3 bucket (object storage)\n",
    "    # before it is pushed to the catalog.\n",
    "    s3_path = f\"s3://{TEMP_S3_BUCKET}/{client.owner_id}/{client.station_name}\"\n",
    "    staged_files.append (f\"{s3_path}/{first_filename}\") # save it for later\n",
    "\n",
    "    # We can also download the file locally to the server, but this is useful only in local mode\n",
    "    local_path = None\n",
    "\n",
    "    # Call the staging service\n",
    "    client.staging(first_filename, TIMEOUT, s3_path=s3_path, tmp_download_path=local_path)\n",
    "\n",
    "    # Then we can check when the staging has finished by calling the check status service\n",
    "    while True:\n",
    "        status = client.staging_status(first_filename, TIMEOUT)\n",
    "        print (f\"Staging status for {first_filename!r}: {status.value}\")\n",
    "        if status in [EDownloadStatus.DONE, EDownloadStatus.FAILED]:\n",
    "            print(\"\\n\")\n",
    "            break\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba922daf-0aad-4cf8-8755-cd87e40e8942",
   "metadata": {},
   "source": [
    "### Use the STAC catalog\n",
    "\n",
    "<mark>TODO: this part must be completed and replaced by the StacClient</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f4a28-49ac-4772-836f-2266d9920324",
   "metadata": {},
   "source": [
    "#### Add a new collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5d52f-9206-4505-a127-5bc87bcb082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "# Add a new collection \n",
    "\n",
    "COLLECTION = \"my_collection\"\n",
    "\n",
    "collection = {\n",
    "            \"id\": COLLECTION,\n",
    "            \"type\": \"Collection\",\n",
    "            \"description\": \"This is my collection description\",\n",
    "            \"stac_version\": \"1.0.0\",\n",
    "            \"owner\": stac_client.owner_id\n",
    "        }\n",
    "\n",
    "# Clean the existing collection, if any\n",
    "requests.delete(f\"{stac_client.href_catalog}/catalog/collections/{stac_client.owner_id}:{COLLECTION}\", **stac_client.apikey_headers, stream=True)\n",
    "\n",
    "# Create it from new\n",
    "post_response = requests.post(f\"{stac_client.href_catalog}/catalog/collections\", json=collection, **stac_client.apikey_headers)\n",
    "post_response.raise_for_status()\n",
    "\n",
    "# See my personal catalog information\n",
    "response = requests.get(f\"{stac_client.href_catalog}/catalog/catalogs/{stac_client.owner_id}\", **stac_client.apikey_headers)\n",
    "response.raise_for_status()\n",
    "print (f\"My catalog information:\\n{json.dumps (json.loads (response.content), indent=2)}\")\n",
    "\n",
    "# See my collection information\n",
    "response = requests.get(f\"{stac_client.href_catalog}/catalog/collections/{stac_client.owner_id}:{COLLECTION}\", **stac_client.apikey_headers)\n",
    "response.raise_for_status()\n",
    "print (f\"\\nMy collection information:\\n{json.dumps (json.loads (response.content), indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9474a-be39-4983-9e27-d43046859ade",
   "metadata": {},
   "source": [
    "#### Add new items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb97df-6b77-4ac9-b42f-645d02ae964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will add one Auxip and one Cadip file that were staged from the previous steps\n",
    "for s3_file in staged_files:\n",
    "\n",
    "    # Let's use item ID = filename\n",
    "    print(f\"\\nAdd catalog item from: {s3_file!r}\")\n",
    "    item_id = os.path.basename(s3_file)\n",
    "    \n",
    "    item = {\n",
    "                \"id\": item_id,\n",
    "                \"bbox\": [-94.6334839, 37.0332547, -94.6005249, 37.0595608],\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [\n",
    "                        [\n",
    "                            [-94.6334839, 37.0595608],\n",
    "                            [-94.6334839, 37.0332547],\n",
    "                            [-94.6005249, 37.0332547],\n",
    "                            [-94.6005249, 37.0595608],\n",
    "                            [-94.6334839, 37.0595608],\n",
    "                        ]\n",
    "                    ],\n",
    "                },\n",
    "                \"collection\": COLLECTION,\n",
    "                \"properties\": {\n",
    "                    \"gsd\": 0.5971642834779395,\n",
    "                    \"width\": 2500,\n",
    "                    \"height\": 2500,\n",
    "                    \"datetime\": \"2000-02-02T00:00:00Z\",\n",
    "                    \"proj:epsg\": 3857,\n",
    "                    \"orientation\": \"nadir\",\n",
    "                    \"owner_id\": stac_client.owner_id,\n",
    "                },\n",
    "                \"stac_extensions\": [],\n",
    "                \"assets\": {\n",
    "                    \"file\": {\n",
    "                        \"href\": s3_file,\n",
    "                        \"type\": \"image/tiff; application=geotiff; profile=cloud-optimized\",\n",
    "                        \"title\": \"NOAA STORM COG\",\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "\n",
    "    # WARNING: after this, the staged file is moved from the temporary to the final bucket,\n",
    "    # so this cell can be run only once, or you'll need to stage the files again.\n",
    "    \n",
    "    # post_response = requests.post(f\"{stac_client.href_catalog}/catalog/collections/{stac_client.owner_id}:{COLLECTION}/items\", json=item, **stac_client.apikey_headers)\n",
    "    # post_response.raise_for_status()\n",
    "    \n",
    "    response = requests.get(f\"{stac_client.href_catalog}/catalog/collections/{stac_client.owner_id}:{COLLECTION}/items/{item_id}\", **stac_client.apikey_headers)\n",
    "    response.raise_for_status()\n",
    "    inserted_item = json.loads (response.content)\n",
    "    print (f\"Saved item in the catalog:\\n{json.dumps (inserted_item, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15f3d0-e3ae-4ab4-9fe6-243615b425bc",
   "metadata": {},
   "source": [
    "<mark>TODO: demonstrate the other catalog endpoints</mark>\n",
    "\n",
    "NOTE: also use the endpoints from the SWAGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3cba16-2c48-4f7a-8bfb-cd91820e5573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
